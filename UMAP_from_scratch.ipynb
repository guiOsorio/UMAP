{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48b1c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fefa7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, learning_rate=0.01, n_iters=10000):\n",
    "        self.lr = learning_rate\n",
    "        self.n_iters = n_iters\n",
    "        self.activation_func = self._unit_step_func\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "    \n",
    "    def _unit_step_func(self, X):\n",
    "        return np.where(X>0, 1, 0)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        labels = np.array([1 if i > 0 else 0 for i in y])\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            \n",
    "            for idx, x_i in enumerate(X):\n",
    "                \n",
    "                # Input layer dot weights layer\n",
    "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
    "                \n",
    "                # Result of operation above activated into a binary output (model prediction)\n",
    "                y_predicted = self._unit_step_func(linear_output)\n",
    "                \n",
    "                # Perceptron update rule\n",
    "                update = (labels[idx]-y_predicted) * self.lr\n",
    "                self.weights += update * x_i\n",
    "                self_bias += update\n",
    "                               \n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(self.weights, X) + self.bias\n",
    "        y_predicted = self._unit_step_func(linear_output)\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f9b694b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>island</th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>male</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adelie</td>\n",
       "      <td>Torgersen</td>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "      <td>female</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     island  bill_length_mm  bill_depth_mm  flipper_length_mm  \\\n",
       "0  Adelie  Torgersen            39.1           18.7              181.0   \n",
       "1  Adelie  Torgersen            39.5           17.4              186.0   \n",
       "2  Adelie  Torgersen            40.3           18.0              195.0   \n",
       "3  Adelie  Torgersen             NaN            NaN                NaN   \n",
       "4  Adelie  Torgersen            36.7           19.3              193.0   \n",
       "\n",
       "   body_mass_g     sex  year  \n",
       "0       3750.0    male  2007  \n",
       "1       3800.0  female  2007  \n",
       "2       3250.0  female  2007  \n",
       "3          NaN     NaN  2007  \n",
       "4       3450.0  female  2007  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = pd.read_csv(\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/c19a904462482430170bfe2c718775ddb7dbb885/inst/extdata/penguins.csv\")\n",
    "penguins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c89f0ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adelie       146\n",
       "Gentoo       119\n",
       "Chinstrap     68\n",
       "Name: species, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penguins = penguins.dropna()\n",
    "penguins.species.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4da293f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bill_length_mm</th>\n",
       "      <th>bill_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.1</td>\n",
       "      <td>18.7</td>\n",
       "      <td>181.0</td>\n",
       "      <td>3750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>186.0</td>\n",
       "      <td>3800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>193.0</td>\n",
       "      <td>3450.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39.3</td>\n",
       "      <td>20.6</td>\n",
       "      <td>190.0</td>\n",
       "      <td>3650.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bill_length_mm  bill_depth_mm  flipper_length_mm  body_mass_g\n",
       "0            39.1           18.7              181.0       3750.0\n",
       "1            39.5           17.4              186.0       3800.0\n",
       "2            40.3           18.0              195.0       3250.0\n",
       "4            36.7           19.3              193.0       3450.0\n",
       "5            39.3           20.6              190.0       3650.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_cols = penguins.iloc[:, 2:6]\n",
    "int_cols.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "640ddc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improvements on lines 62, 80, 132\n",
    "\n",
    "class my_UMAP:\n",
    "    def __init__(self, learning_rate=0.01, nearest_neighbors=15):\n",
    "        self.lr = learning_rate\n",
    "        self.nn = nearest_neighbors\n",
    "        \n",
    "    def _euclidean_dist_all(self, df_nums): # df_nums needs to be composed on only integer values\n",
    "        all_dists = {} # dict with key as index of value \n",
    "        i = 0\n",
    "        \n",
    "        for p in int_cols.iloc[:].values:\n",
    "            temp = np.array([])\n",
    "\n",
    "            for pp in int_cols.iloc[:].values:\n",
    "                dist = np.linalg.norm(p - pp)\n",
    "                temp = np.append(temp, dist)\n",
    "\n",
    "            all_dists[i] = temp\n",
    "            i += 1\n",
    "        \n",
    "        return all_dists\n",
    "    \n",
    "    def graph_original_nns(self, dists, show_visuals, ngraphs):\n",
    "        \n",
    "        dists_dict = {}\n",
    "        \n",
    "        for key in dists:\n",
    "            \n",
    "            all_curr_dists = dists[key] # dists[key] is an array with the values for all distances from the point at index 'key'\n",
    "                                            # (from original data) which preserves the original order of the data points\n",
    "                                 \n",
    "            min_inds = all_curr_dists.argsort()[:self.nn+1]\n",
    "            min_inds = min_inds[min_inds != key] # stores the values of the indexes of the nearest neighbors\n",
    "            \n",
    "            # Create array with the distances of the point 'key' to its nearest neighbors\n",
    "            curr_dists_nns = np.array([])\n",
    "            for ind in min_inds:\n",
    "                curr_dists_nns = np.append(curr_dists_nns, all_curr_dists[ind]) # values are already sorted\n",
    "            \n",
    "            # Plot graphs -- Optional\n",
    "            if show_visuals == True and key <= (ngraphs-1):\n",
    "            \n",
    "                plt.plot(curr_dists_nns, np.zeros_like(curr_dists_nns), 'ko')\n",
    "                plt.plot(0, 0, 'c*')\n",
    "                plt.annotate('Origin point', (0, 0), xytext=(0, 2), arrowprops=dict(arrowstyle='<-', color='cyan', linewidth=2))\n",
    "                plt.xlabel(f'Nearest {self.nn} Neighbors')\n",
    "                plt.ylim(-0.5, 5)\n",
    "                plt.show()\n",
    "\n",
    "                print('Distances to nearest neighbors: ', curr_dists_nns)\n",
    "            \n",
    "            # Nested dictionary to store useful info about a data point\n",
    "            dists_dict[key] = {}\n",
    "            dists_dict[key]['nns_indexes'] = min_inds\n",
    "            dists_dict[key]['dists_to_nns'] = curr_dists_nns\n",
    "            dists_dict[key]['all_dists'] = all_curr_dists\n",
    "        \n",
    "        return dists_dict\n",
    "            \n",
    "    \n",
    "    def graph_similarity_scores(self, dists_dict, show_visuals, ngraphs, theta=1): ################ TRAIN THETA\n",
    "    \n",
    "        i = 0\n",
    "        \n",
    "        for k, d in dists_dict.items():\n",
    "            \n",
    "            dists_nns_only = d['dists_to_nns']\n",
    "            nneighbor = dists_nns_only[0]\n",
    "            similarity_scores = np.array([])\n",
    "            \n",
    "            for dist in dists_nns_only:\n",
    "                \n",
    "                # Calculate similarity scores of nearest neighbors\n",
    "                similarity_score = np.exp(-(dist-nneighbor)/theta)\n",
    "                similarity_scores = np.append(similarity_scores, similarity_score)\n",
    "            \n",
    "            \n",
    "            # Plot graphs -- Optional\n",
    "            if show_visuals == True and i <= (ngraphs-1):  ######## FIX SMOOTHNESS OF LINE -- EXPONENTIAL INSTEAD OF QUADRATIC\n",
    "                \n",
    "                plt.plot(dists_nns_only, similarity_scores, 'ko')\n",
    "\n",
    "            # ATTEMPT TO DRAW A LINE TO CONNECT POINTS -- LOOKING FOR EXPONENTIAL, NOT QUADRATIC KIND\n",
    "    #             x_new = np.linspace(dists_nns_only[0], dists_nns_only[-1],500)\n",
    "    #             f = interp1d(dists_nns_only, similarity_scores, kind='quadratic')\n",
    "    #             y_smooth=f(x_new)\n",
    "    #             plt.plot(x_new, y_smooth)\n",
    "\n",
    "                plt.xlabel(f\"Nearest {self.nn} Neighbors' SSs\")\n",
    "                plt.ylim(-0.5, 1.5)\n",
    "                plt.show()\n",
    "                \n",
    "                print('Similarity Scores: ', similarity_scores)\n",
    "                i += 1\n",
    "            \n",
    "            dists_dict[k]['similarity_scores'] = similarity_scores\n",
    "        \n",
    "        return dists_dict\n",
    "    \n",
    "    \n",
    "    def calc_sss(self, dists_dict):\n",
    "        \n",
    "        inds_sss = []\n",
    "        \n",
    "        # loop through all keys and values in dists_dict\n",
    "        for key, values in dists_dict.items():\n",
    "            dists_dict[key]['SSSs'] = {}\n",
    "        # Loop through nns_indexes and previously calculated distances\n",
    "            for ind, ss in zip(values['nns_indexes'], values['similarity_scores']):\n",
    "                temp_inds = (key, ind)\n",
    "                temp_inds_arr = list(temp_inds)\n",
    "                temp_inds_arr.sort()\n",
    "                \n",
    "                # if already calculated one way, does not to be calculated the other way\n",
    "                if temp_inds_arr in inds_sss:\n",
    "                    # Have value be equal to of the one already calculated\n",
    "                        # take index of other value (not 'key') => ind\n",
    "                    tup = tuple(temp_inds_arr)\n",
    "                    sss = dists_dict[ind]['SSSs'][tup]\n",
    "                    dists_dict[key]['SSSs'][temp_inds] = sss\n",
    "                    \n",
    "                else:\n",
    "                    s1 = ss\n",
    "                    \n",
    "                    # Find s2\n",
    "                    for ind2, ss2 in zip(dists_dict[ind]['nns_indexes'], dists_dict[ind]['similarity_scores']):\n",
    "                        if ind2 == key:\n",
    "                            s2 = ss2\n",
    "                        else:\n",
    "                            s2 = s1 # if s2 does not exist due to the nns not matching, make s2 the same as s1\n",
    "                            ######## ABOVE IS NOT IDEAL\n",
    "                            \n",
    "                    sss = (s1+s2) - s1*s2\n",
    "                    \n",
    "                    inds_sss.append(temp_inds_arr)\n",
    "                    dists_dict[key]['SSSs'][temp_inds] = sss\n",
    "            \n",
    "        return dists_dict\n",
    "            \n",
    "        \n",
    "        # if tuple between \n",
    "        \n",
    "    \n",
    "    def fit(self, df_nums, show_visuals=False, ngraphs=5):\n",
    "        \n",
    "        # Step 1 - calculate distances between each pair of points -> euclidean distance -- DONE\n",
    "        all_dists = self._euclidean_dist_all(df_nums)\n",
    "        \n",
    "        # Step 2 - make a graph for each point where the origin is that point and the other points are placed on the \n",
    "        #    x-axis in relation to their distance to the origin point -- DONE\n",
    "        dists_dict = self.graph_original_nns(all_dists, show_visuals=show_visuals, ngraphs=ngraphs) ######## SEE WHERE *args, **kwargs CAN BE USED\n",
    "        \n",
    "        # Step 3 - decide on number of high dimensional neighbors (including the point itself, common value is 15) -- DONE\n",
    "        \n",
    "        # Step 4 - draw a curve based on the distances and nn parameter. The curve is drawn in such a way that the sum of \n",
    "        #    the y-coordinates that match up with the number of neighbors equals the log2(nns) -- INCOMPLETE\n",
    "        dists_dict = self.graph_similarity_scores(dists_dict, show_visuals=show_visuals, ngraphs=ngraphs)\n",
    "        \n",
    "        # Step 5 - converge similarity scores between the same points into one --> symmetrical similarity score (SSS)\n",
    "            # SSS = (S1+S2) - S1*S2\n",
    "            # dists_dict -> first key represents the index of the origin point in the original data\n",
    "                # inside that key we have -> 'nns_indexes' (in original data, ordered), 'dists_to_nns' (ordered),\n",
    "                    # 'all_dists' (ordered based on original data), 'similarity_scores' (ordered)\n",
    "        dists_dict = self.calc_sss(dists_dict)\n",
    "        print(dists_dict[20]['SSSs'], dists_dict[20]['nns_indexes'])\n",
    "        print(dists_dict[17]['SSSs'], dists_dict[17]['nns_indexes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40d1a5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(20, 76): 1.0, (20, 17): 0.6043986223184963, (20, 80): 0.29912459864977636} [76 17 80]\n",
      "{(17, 80): 1.0, (17, 20): 0.6043986223184963, (17, 76): 0.567075742492198} [80 20 76]\n"
     ]
    }
   ],
   "source": [
    "test = my_UMAP(nearest_neighbors = 3)\n",
    "test_dict = test.fit(int_cols, show_visuals=False)\n",
    "\n",
    "\n",
    "\n",
    "# nneighbor = test_dict[1]\n",
    "# for i in test_dict[0][1:]:\n",
    "#     print(np.exp(-(i-nneighbor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113496a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', context='notebook', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615398d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(penguins.drop(\"year\", axis=1), hue='species');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67693816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964aaba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e71941",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguin_data = penguins[\n",
    "    [\n",
    "        \"bill_length_mm\",\n",
    "        \"bill_depth_mm\",\n",
    "        \"flipper_length_mm\",\n",
    "        \"body_mass_g\",\n",
    "    ]\n",
    "].values\n",
    "scaled_penguin_data = StandardScaler().fit_transform(penguin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f28fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],\n",
    "    c=[sns.color_palette()[x] for x in penguins.species.map({\"Adelie\":0, \"Chinstrap\":1, \"Gentoo\":2})])\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the Penguin dataset', fontsize=24);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
